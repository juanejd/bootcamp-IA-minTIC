{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fd09e23",
   "metadata": {},
   "source": [
    "Aprendizaje por refuerzo\n",
    "\n",
    "Un robot es un mundo de 4 celdas lineales (0, 1, 2, 3) donde la celda # 3 es el objetivo(recompensa). El robot puede moverse de izquierda a derecha\n",
    "\n",
    "- Agente (sistema, maquina, robot, etc.)\n",
    "- Entorno (El mundo que rodea al agente) ---> las 4 celdas\n",
    "- Estado (Posicion del agente dentro del entorno) ---> [0, 1, 2, 3]\n",
    "- Accion (Deision a tomar por parte del agente dentro de un estado) ---> izquierda - derecha\n",
    "- Recompensa (Valor que se le da al agente tras llegar a un estado) ---> Celda # 3\n",
    "- Episodio (Conjunto de acciones desde el primer al ultimo estado) ---> acciones\n",
    "- PolÃ­tica (Estrategia que se le dal agente para saber que accion tomar en cada estado) --->\n",
    "\n",
    "Descripcion del entorno\n",
    "\n",
    "- Celdas: [0, 1, 2, 3]\n",
    "- Inicio: Celda #0\n",
    "- Objetivo (recompensa): Celda #3\n",
    "- Acciones posibles: Izq(0) - Der(1)\n",
    "  Si el robot se sale del rango, se queda en el mismo lugar. Al llegar a la celda #3 termina el Episodio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09bb05f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "117225fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros\n",
    "num_states = 4  # celdas\n",
    "num_actions = 2  # 0: izquierda, 1: derecha\n",
    "\n",
    "q_table = np.zeros((num_states, num_actions))\n",
    "\n",
    "alpha = 0.1  # Taza de aprendizaje\n",
    "gama = 0.9  # Factor de descuento\n",
    "epsilon = 0.1  # Probabilidad de exploracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb9480f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para tomar una accion\n",
    "def choose_action(state):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return random.randint(0, 1)  # exploracion\n",
    "    else:\n",
    "        return np.argmax(q_table[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1f82f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion del retorno\n",
    "def step(state, action):\n",
    "    if action == 0:  # izquierda\n",
    "        next_step = max(0, state - 1)\n",
    "    else:\n",
    "        next_step = min(num_states - 1, state + 1)\n",
    "    reward = 1 if next_step == 3 else 0\n",
    "    done = next_step == 3\n",
    "    return next_step, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d518376",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 100\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        action = choose_action(state)\n",
    "        next_step, reward, done = step(state, action)\n",
    "\n",
    "        previous_value = q_table[state, action]\n",
    "        next_step_max = np.max(q_table[next_step])\n",
    "\n",
    "        # Actualizamos el Q-valor\n",
    "        q_table[state, action] = previous_value + alpha * (\n",
    "            reward + gama * next_step_max\n",
    "        )\n",
    "        state = next_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c19871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Q-table final\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
